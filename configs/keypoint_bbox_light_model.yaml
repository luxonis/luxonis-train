# Example configuration for training a predefined light keypoint-detection model

model:
  name: keypoint_detection_light
  predefined_model:
    name: KeypointDetectionModel
    variant: light
    params:
      loss_params:
        iou_type: "ciou"

        # Should be 7.5 * accumulate_grad_batches for the best results
        iou_loss_weight: 60

        # Should be 0.5 * accumulate_grad_batches for the best results
        class_loss_weight: 4

        # Should be 12 * accumulate_grad_batches for the best results
        regr_kpts_loss_weight: 96

        # Should be 1 * accumulate_grad_batches for the best results
        vis_kpts_loss_weight: 8

loader:
  params:
    dataset_name: coco_test

trainer:
  precision: "16-mixed"
  preprocessing:
    train_image_size: [384, 512]
    keep_aspect_ratio: true
    normalize:
      active: true
      params:
        mean: [0., 0., 0.]
        std: [1, 1, 1]

  batch_size: 8
  epochs: 300
  n_workers: 4
  validation_interval: 10
  n_log_images: 8
  gradient_clip_val: 10

  callbacks:
    - name: EMACallback
      params:
        decay: 0.9999
        use_dynamic_decay: True
        decay_tau: 2000
    - name: ConvertOnTrainEnd
    # For best results, always accumulate gradients to
    # effectively use 64 batch size
    - name: GradientAccumulationScheduler
      params:
        # warmup phase is 3 epochs
        scheduling:
          0: 1
          1: 4
          2: 8

  training_strategy:
    name: "TripleLRSGDStrategy"
    params:
      warmup_epochs: 3
      warmup_bias_lr: 0.0
      warmup_momentum: 0.8
      lr: 0.01
      lre: 0.0001
      momentum: 0.937
      weight_decay: 0.0005
      nesterov: True
      cosine_annealing: False
