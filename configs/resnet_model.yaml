
model:
  name: resnet50_classification
  nodes:
    - name: ResNet
      variant: "50"
      download_weights: True

    - name: ClassificationHead
      inputs:
        - ResNet
    
    - name: SegmentationHead
      inputs:
        - ResNet

  losses:
    - name: CrossEntropyLoss
      attached_to: ClassificationHead

  metrics:
    - name: Accuracy
      is_main_metric: true
      attached_to: ClassificationHead

tracker:
  project_name: coco_test
  save_directory: output
  is_tensorboard: True
  is_wandb: False
  wandb_entity: luxonis
  is_mlflow: False

dataset:
  name: coco_test
  train_view: train
  val_view: val
  test_view: test

trainer:
  accelerator: auto
  devices: auto
  strategy: auto

  num_sanity_val_steps: 1
  profiler: null
  verbose: True
  batch_size: 4
  accumulate_grad_batches: 1
  epochs: &epochs 1
  num_workers: 8
  train_metrics_interval: -1
  validation_interval: 1
  num_log_images: 8
  skip_last_batch: True
  main_head_index: 0
  log_sub_losses: True
  save_top_k: 3

  preprocessing:
    train_image_size: [&height 256, &width 320]
    keep_aspect_ratio: False
    train_rgb: True
    normalize:
      active: True
    augmentations:
      - name: Defocus
        params:
          p: 0.1
      - name: Sharpen
        params:
          p: 0.1
      - name: Flip
      - name: RandomRotate90
      - name: Mosaic4
        params:
          out_width: *width
          out_height: *height

  callbacks:
    - name: LearningRateMonitor
      params:
        logging_interval: step
    - name: MetadataLogger
      params:
        hyperparams: ["trainer.epochs", trainer.batch_size]
    - name: EarlyStopping
      params:
        patience: 3
        monitor: val/loss
        mode: min
        verbose: true
    - name: DeviceStatsMonitor
    - name: ExportOnTrainEnd
    - name: TestOnTrainEnd

  optimizer:
    name: SGD
    params:
      lr: 0.02
      momentum: 0.937
      nesterov: True
      weight_decay: 0.0005

  scheduler:
    name: CosineAnnealingLR
    params:
      T_max: *epochs
      eta_min: 0

exporter:
  onnx:
    opset_version: 11
  blobconverter:
    active: True
    shaves: 8

tuner:
  params:
    trainer.optimizer.name_categorical: ["Adam", "SGD"]
    trainer.optimizer.params.lr_float: [0.0001, 0.001]
    trainer.batch_size_int: [4, 16, 4]
