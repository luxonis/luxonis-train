# Example configuration for training a predefined heavy instance segmentation model

model:
  name: instance_segmentation_heavy
  predefined_model:
    name: InstanceSegmentationModel
    params:
      variant: heavy
      loss_params:
        bbox_loss_weight: 60 # Should be 7.5 * accumulate_grad_batches for best results
        class_loss_weight: 4 # Should be 0.5 * accumulate_grad_batches for best results
        dfl_loss_weight: 12 # Should be 1.5 * accumulate_grad_batches for best results

loader:
  params:
    dataset_name: coco_test

trainer:
  precision: "16-mixed"
  preprocessing:
    train_image_size: [384, 512]
    keep_aspect_ratio: true
    normalize:
      active: true
      params:
        mean: [0., 0., 0.]
        std: [1, 1, 1]

  batch_size: 8
  epochs: 300
  n_workers: 4
  validation_interval: 10
  n_log_images: 8
  gradient_clip_val: 10

  callbacks:
    - name: EMACallback
      params:
        decay: 0.9999
        use_dynamic_decay: True
        decay_tau: 2000
    - name: ExportOnTrainEnd
    - name: TestOnTrainEnd
    - name: GradientAccumulationScheduler
      params:
        scheduling: # warmup phase is 3 epochs
          0: 1
          1: 4
          2: 8 # For best results, always accumulate gradients to effectively use 64 batch size

  training_strategy:
    name: "TripleLRSGDStrategy"
    params:
      warmup_epochs: 3
      warmup_bias_lr: 0.0
      warmup_momentum: 0.8
      lr: 0.01
      lre: 0.0001
      momentum: 0.937
      weight_decay: 0.0005
      nesterov: True
      cosine_annealing: False
